{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation coefficient: 0.952\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Example data (Replace with your actual values)\n",
    "ground_shannon = [2.1, 2.4, 2.0, 2.5, 2.3, 2.2, 2.6, 2.0, 2.7, 2.8, 2.3, 2.1, 2.4, 2.5]\n",
    "image_shannon = [2.0, 2.3, 2.1, 2.4, 2.2, 2.1, 2.5, 2.1, 2.6, 2.7, 2.2, 2.0, 2.3, 2.4]\n",
    "\n",
    "# Compute Spearman's correlation\n",
    "rho, p_value = stats.spearmanr(ground_shannon, image_shannon)\n",
    "\n",
    "print(f\"Spearman correlation coefficient: {rho:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_shannon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.928\n",
      "Model:                            OLS   Adj. R-squared:                  0.922\n",
      "Method:                 Least Squares   F-statistic:                     153.9\n",
      "Date:                Thu, 06 Feb 2025   Prob (F-statistic):           3.33e-08\n",
      "Time:                        10:15:16   Log-Likelihood:                 18.257\n",
      "No. Observations:                  14   AIC:                            -32.51\n",
      "Df Residuals:                      12   BIC:                            -31.24\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1896      0.206     -0.922      0.375      -0.637       0.258\n",
      "x1             1.1145      0.090     12.407      0.000       0.919       1.310\n",
      "==============================================================================\n",
      "Omnibus:                       10.303   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                6.418\n",
      "Skew:                          -1.559   Prob(JB):                       0.0404\n",
      "Kurtosis:                       4.134   Cond. No.                         29.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf-metal/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(image_shannon)  # Add intercept\n",
    "y = ground_shannon\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Ground_Shannon   R-squared:                       0.033\n",
      "Model:                            OLS   Adj. R-squared:                 -0.021\n",
      "Method:                 Least Squares   F-statistic:                    0.6162\n",
      "Date:                Thu, 06 Feb 2025   Prob (F-statistic):              0.443\n",
      "Time:                        10:17:13   Log-Likelihood:               -0.13874\n",
      "No. Observations:                  20   AIC:                             4.277\n",
      "Df Residuals:                      18   BIC:                             6.269\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     1.9201      0.538      3.569      0.002       0.790       3.050\n",
      "Hyperspectral_Shannon     0.1795      0.229      0.785      0.443      -0.301       0.660\n",
      "==============================================================================\n",
      "Omnibus:                        1.694   Durbin-Watson:                   2.224\n",
      "Prob(Omnibus):                  0.429   Jarque-Bera (JB):                0.952\n",
      "Skew:                           0.003   Prob(JB):                        0.621\n",
      "Kurtosis:                       1.931   Cond. No.                         26.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Example: Ground data (20 locations)\n",
    "ground_shannon = np.array([2.1, 2.4, 2.0, 2.5, 2.3, 2.2, 2.6, 2.0, 2.7, 2.8, \n",
    "                           2.3, 2.1, 2.4, 2.5, 2.2, 2.3, 2.1, 2.0, 2.6, 2.7])\n",
    "\n",
    "# Example: Hyperspectral data (4,302 values)\n",
    "hyperspectral_shannon = np.random.normal(2.3, 0.2, 4302)  # Simulated random values\n",
    "\n",
    "# Step 1: Aggregate hyperspectral data (match ground locations)\n",
    "# You can use mean, median, or another method\n",
    "aggregated_hyperspectral = np.random.choice(hyperspectral_shannon, size=20, replace=False)\n",
    "\n",
    "# Step 2: Create a DataFrame\n",
    "df = pd.DataFrame({\"Ground_Shannon\": ground_shannon, \"Hyperspectral_Shannon\": aggregated_hyperspectral})\n",
    "\n",
    "# Step 3: Fit the Generalized Linear Model (GLM)\n",
    "X = sm.add_constant(df[\"Hyperspectral_Shannon\"])  # Add intercept\n",
    "y = df[\"Ground_Shannon\"]\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. aggregated_hyperspectral 1.835981189909874\n",
      "min. hyperspectral_shannon 1.6628182554287034\n",
      "max. aggregated_hyperspectral 2.853984338858284\n",
      "max. hyperspectral_shannon 3.0244958733173846\n"
     ]
    }
   ],
   "source": [
    "print(f'min. aggregated_hyperspectral {min(aggregated_hyperspectral)}')\n",
    "print(f'min. hyperspectral_shannon {min(hyperspectral_shannon)}')\n",
    "print(f'max. aggregated_hyperspectral {max(aggregated_hyperspectral)}')\n",
    "print(f'max. hyperspectral_shannon {max(hyperspectral_shannon)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Aggregated Values\n",
      "0            1.651747\n",
      "1            1.979809\n",
      "2            2.051979\n",
      "3            2.102033\n",
      "4            2.140364\n",
      "5            2.176692\n",
      "6            2.205682\n",
      "7            2.235960\n",
      "8            2.263369\n",
      "9            2.290788\n",
      "10           2.317196\n",
      "11           2.344820\n",
      "12           2.371344\n",
      "13           2.398446\n",
      "14           2.426963\n",
      "15           2.464066\n",
      "16           2.506169\n",
      "17           2.555718\n",
      "18           2.634701\n",
      "19           3.085248\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simulated hyperspectral values (4,000 samples)\n",
    "np.random.seed(42)\n",
    "hyperspectral_values = np.random.normal(2.3, 0.2, 4000)  # Example data\n",
    "\n",
    "print(f'max. hyperspectral_values {max(hyperspectral_values)}')\n",
    "print(f'min. hyperspectral_values {min(hyperspectral_values)}')\n",
    "\n",
    "# Step 1: Get min and max values\n",
    "min_value = np.min(hyperspectral_values)\n",
    "max_value = np.max(hyperspectral_values)\n",
    "\n",
    "# Step 2: Create quantiles (dividing data into 18 bins because 2 slots are taken by min/max)\n",
    "quantiles = np.percentile(hyperspectral_values, np.linspace(5, 95, 18))\n",
    "\n",
    "# Step 3: Sample proportionally from each quantile bin\n",
    "aggregated_values = [min_value] + list(quantiles) + [max_value]\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df_aggregated = pd.DataFrame({\"Aggregated Values\": aggregated_values})\n",
    "print(df_aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal,ogr,osr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"D:/MasterThesis/final_hs_data_folder/\"\n",
    "hdr_file = f\"{file}.hdr\"\n",
    "# Check if files exist\n",
    "if os.path.exists(file):\n",
    "    print(f\"File exists: {file}\")\n",
    "else:\n",
    "    print(f\"File not found: {file}\")\n",
    "\n",
    "if os.path.exists(hdr_file):\n",
    "    print(f\"HDR File exists: {hdr_file}\")\n",
    "else:\n",
    "    print(f\"HDR File not found: {hdr_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file = \"test_data/Shannon_20\"\n",
    "hdr_file = f\"{file}.hdr\"\n",
    "# Check if files exist\n",
    "if os.path.exists(file):\n",
    "    print(f\"File exists: {file}\")\n",
    "else:\n",
    "    print(f\"File not found: {file}\")\n",
    "\n",
    "if os.path.exists(hdr_file):\n",
    "    print(f\"HDR File exists: {hdr_file}\")\n",
    "else:\n",
    "    print(f\"HDR File not found: {hdr_file}\")\n",
    "\n",
    "img_open = gdal.Open(file)\n",
    "\n",
    "# read a few key properties of the image\n",
    "nbands = img_open.RasterCount\n",
    "ncols = img_open.RasterXSize\n",
    "nrows = img_open.RasterYSize\n",
    "\n",
    "print(\"\\n\".join([\"Bands:\\t\"+str(nbands),\"Cols (RasterXSize):\\t\"+str(ncols),\"Rows (RasterYSize):\\t\"+str(nrows)]))\n",
    "\n",
    "# read and display\n",
    "shannon_diversity_map = img_open.ReadAsArray()\n",
    "#shannon_diversity_map = np.where(shannon_diversity_map == -9999, np.nan, img_red)\n",
    "plt.rcParams[\"figure.figsize\"] = [15,20]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.imshow(shannon_diversity_map)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
